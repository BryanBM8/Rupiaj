{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5ssa1Dim_Tq",
        "outputId": "3ca10c67-1192-472c-f459-270bcf6c36be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "i3uW9XL4lnbw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6bBc1MEoZ2FR"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/drive/MyDrive/CompVis Projek/UANGUVTERBARU\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "76-f6oQ_lnb0"
      },
      "outputs": [],
      "source": [
        "names = ['1 RIBU ASLI', '1 RIBU PALSU', '10 RIBU ASLI', '10 RIBU PALSU',\n",
        "         '100 RIBU ASLI', '100 RIBU PALSU', '20 RIBU ASLI', '20 RIBU PALSU',\n",
        "         '5 RIBU ASLI', '5 RIBU PALSU', '50 RIBU ASLI', '50 RIBU PALSU']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_image(image, bbox):\n",
        "    augmented_images = []\n",
        "    augmented_bboxes = []\n",
        "\n",
        "    # Rotasi kecil\n",
        "    for angle in [-10, 10]:\n",
        "        h, w = image.shape[:2]\n",
        "        rotation_matrix = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)\n",
        "        rotated = cv2.warpAffine(image, rotation_matrix, (w, h))\n",
        "\n",
        "        # Update bounding box\n",
        "        corners = np.array([\n",
        "            [bbox[0], bbox[1], 1],\n",
        "            [bbox[2], bbox[1], 1],\n",
        "            [bbox[2], bbox[3], 1],\n",
        "            [bbox[0], bbox[3], 1]\n",
        "        ])\n",
        "        rotated_corners = np.dot(rotation_matrix, corners.T).T\n",
        "        x_min, y_min = np.min(rotated_corners, axis=0)[:2]\n",
        "        x_max, y_max = np.max(rotated_corners, axis=0)[:2]\n",
        "\n",
        "        # Pastikan IoU valid\n",
        "        rotated_bbox = [int(x_min), int(y_min), int(x_max), int(y_max)]\n",
        "        iou = calculate_iou(bbox, rotated_bbox)\n",
        "        if iou > 0.5:\n",
        "            augmented_images.append(rotated)\n",
        "            augmented_bboxes.append(rotated_bbox)\n",
        "\n",
        "    # Ubah kecerahan\n",
        "    for brightness_factor in [0.8, 1.2]:\n",
        "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "        hsv[:, :, 2] = np.clip(hsv[:, :, 2] * brightness_factor, 0, 255).astype(np.uint8)\n",
        "        bright_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "        augmented_images.append(bright_img)\n",
        "        augmented_bboxes.append(bbox)\n",
        "\n",
        "    noise = np.random.normal(0, 10, image.shape).astype(np.uint8)\n",
        "    noisy_image = cv2.add(image, noise)\n",
        "    augmented_images.append(noisy_image)\n",
        "    augmented_bboxes.append(bbox)\n",
        "\n",
        "    return augmented_images, augmented_bboxes"
      ],
      "metadata": {
        "id": "yeYzh-2j8vp1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iou(boxA, boxB):\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "\n",
        "    # Area overlap\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "\n",
        "    # Area total\n",
        "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
        "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
        "\n",
        "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "    return iou"
      ],
      "metadata": {
        "id": "dmRlMZHd-bik"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i7657Z6vaCGA"
      },
      "outputs": [],
      "source": [
        "# microtext\n",
        "def extract_microtext(image_gray):\n",
        "    edges = cv2.Canny(image_gray, 50, 150)\n",
        "    return np.sum(edges) / edges.size\n",
        "\n",
        "# warna\n",
        "def extract_color(image):\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    hue_mean = np.mean(hsv[:, :, 0])\n",
        "    sat_mean = np.mean(hsv[:, :, 1])\n",
        "    val_mean = np.mean(hsv[:, :, 2])\n",
        "\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    intensity_mean = np.mean(gray)\n",
        "\n",
        "    red_mean = np.mean(image[:, :, 2])\n",
        "    green_mean = np.mean(image[:, :, 1])\n",
        "    blue_mean = np.mean(image[:, :, 0])\n",
        "\n",
        "    return hue_mean, sat_mean, val_mean, intensity_mean, red_mean, green_mean, blue_mean\n",
        "\n",
        "# benang pengaman\n",
        "def detect_thread(image_gray):\n",
        "    _, thresh = cv2.threshold(image_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 15))\n",
        "    thread = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel)\n",
        "    return np.sum(thread) / thread.size\n",
        "\n",
        "\n",
        "def extract_features(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray=cv2.equalizeHist(gray)\n",
        "    microtext_density = extract_microtext(gray)\n",
        "    hue, saturation, value, intensity, red, green, blue = extract_color(image)\n",
        "    thread_density = detect_thread(gray)\n",
        "    return [microtext_density, hue, saturation, value, intensity, red, green, blue, thread_density]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5a2nme0slnb0"
      },
      "outputs": [],
      "source": [
        "def load_dataset(folder_path, resize_dim=(512, 512)):\n",
        "    images_folder = os.path.join(folder_path, \"images\")\n",
        "    labels_folder = os.path.join(folder_path, \"labels\")\n",
        "\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for img_name in os.listdir(images_folder):\n",
        "        if img_name.endswith(\".jpg\"):\n",
        "            img_path = os.path.join(images_folder, img_name)\n",
        "            label_path = os.path.join(labels_folder, os.path.splitext(img_name)[0] + \".txt\")\n",
        "\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None and os.path.exists(label_path):\n",
        "                with open(label_path, \"r\") as f:\n",
        "                    label_data = f.readline().strip().split()\n",
        "                    class_idx = int(label_data[0])\n",
        "                    x, y, w, h = map(float, label_data[1:])\n",
        "                    bbox = [\n",
        "                        int((x - w / 2) * img.shape[1]),\n",
        "                        int((y - h / 2) * img.shape[0]),\n",
        "                        int((x + w / 2) * img.shape[1]),\n",
        "                        int((y + h / 2) * img.shape[0]),\n",
        "                    ]\n",
        "\n",
        "                original_shape = img.shape[:2]\n",
        "                img = cv2.resize(img, resize_dim)\n",
        "                scale_x = resize_dim[1] / original_shape[1]\n",
        "                scale_y = resize_dim[0] / original_shape[0]\n",
        "                bbox = [\n",
        "                    int(bbox[0] * scale_x),\n",
        "                    int(bbox[1] * scale_y),\n",
        "                    int(bbox[2] * scale_x),\n",
        "                    int(bbox[3] * scale_y),\n",
        "                ]\n",
        "                features = extract_features(img)\n",
        "                data.append(features)\n",
        "                labels.append(class_idx)\n",
        "\n",
        "                augmented_images, augmented_bboxes = augment_image(img, bbox)\n",
        "                for aug_img, aug_bbox in zip(augmented_images, augmented_bboxes):\n",
        "                    aug_features = extract_features(aug_img)\n",
        "                    data.append(aug_features)\n",
        "                    labels.append(class_idx)\n",
        "\n",
        "    return np.array(data, dtype=np.float32), np.array(labels, dtype=np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train= load_dataset(dataset_path+'/train/')\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "x_train, y_train= shuffle(x_train, y_train, random_state=42)\n",
        "x_test, y_test=load_dataset(dataset_path+'/test/')\n",
        "x_test, y_test=shuffle(x_test, y_test, random_state=42)"
      ],
      "metadata": {
        "id": "4yRqR1cujGxE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def balance_dataset_undersample(data, labels):\n",
        "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "    min_count = min(counts)\n",
        "\n",
        "    balanced_data = []\n",
        "    balanced_labels = []\n",
        "\n",
        "    label_to_data = {label: [] for label in unique_labels}\n",
        "    for d, l in zip(data, labels):\n",
        "        label_to_data[l].append(d)\n",
        "\n",
        "    for label in unique_labels:\n",
        "        samples = label_to_data[label][:min_count]\n",
        "        balanced_data.extend(samples)\n",
        "        balanced_labels.extend([label] * min_count)\n",
        "\n",
        "    return np.array(balanced_data, dtype=np.float32), np.array(balanced_labels, dtype=np.int32)\n",
        "\n",
        "\n",
        "x_train, y_train= balance_dataset_undersample(x_train, y_train)"
      ],
      "metadata": {
        "id": "XjfshP15kvo0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lqxyy6Qvlnb2",
        "outputId": "f8b6b3c1-4059-4ced-f7d4-a0b96f9d9cf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data per label:\n",
            "Label 0: 1152 data\n",
            "Label 1: 1152 data\n",
            "Label 2: 1152 data\n",
            "Label 3: 1152 data\n",
            "Label 4: 1152 data\n",
            "Label 5: 1152 data\n",
            "Label 6: 1152 data\n",
            "Label 7: 1152 data\n",
            "Label 8: 1152 data\n",
            "Label 9: 1152 data\n",
            "Label 10: 1152 data\n",
            "Label 11: 1152 data\n"
          ]
        }
      ],
      "source": [
        "unique_labels, counts = np.unique(y_train, return_counts=True)\n",
        "\n",
        "print(\"Jumlah data per label:\")\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"Label {label}: {count} data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GjPWnvtwlnb1"
      },
      "outputs": [],
      "source": [
        "def evaluate_with_iou(pred_bboxes, gt_bboxes):\n",
        "    iou_scores = []\n",
        "    for pred, gt in zip(pred_bboxes, gt_bboxes):\n",
        "        iou = calculate_iou(pred, gt)\n",
        "        iou_scores.append(iou)\n",
        "    return np.mean(iou_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPqyTajUlnb3",
        "outputId": "defd915e-75f1-454a-f7f5-ead0a81f94b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  15.0s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  18.2s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  15.2s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  14.8s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  14.8s\n",
            "Best Parameters: {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}\n",
            "Best Cross-Validation Accuracy: 0.394965024350798\n",
            "Test Accuracy: 0.8156028368794326\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1],\n",
        "    'gamma': [1],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2, cv=5)\n",
        "grid.fit(x_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid.best_score_)\n",
        "\n",
        "best_svm = grid.best_estimator_\n",
        "print(\"Test Accuracy:\", best_svm.score(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTP9s5gilnb3",
        "outputId": "4db1c419-8c07-4184-847b-96286f28b2d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.87      0.91       216\n",
            "           1       1.00      0.62      0.77        72\n",
            "           2       0.99      0.81      0.89       186\n",
            "           3       1.00      0.88      0.94        78\n",
            "           4       0.46      1.00      0.63       258\n",
            "           5       1.00      0.72      0.84        90\n",
            "           6       1.00      0.65      0.79       102\n",
            "           7       1.00      0.89      0.94       108\n",
            "           8       0.99      0.74      0.85       108\n",
            "           9       1.00      0.88      0.94       174\n",
            "          10       1.00      0.73      0.84       198\n",
            "          11       1.00      0.66      0.79       102\n",
            "\n",
            "    accuracy                           0.82      1692\n",
            "   macro avg       0.95      0.79      0.84      1692\n",
            "weighted avg       0.91      0.82      0.84      1692\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_svm = best_svm.predict(x_test)\n",
        "print(\"SVM Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_svm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEUzeNlqlnb4",
        "outputId": "90f97436-47ad-4fe3-f413-dcc2b9dac443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'uniform'}\n",
            "Best cross-validated score: 0.8926506648382851\n",
            "KNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       216\n",
            "           1       0.92      0.93      0.92        72\n",
            "           2       0.97      0.94      0.95       186\n",
            "           3       1.00      1.00      1.00        78\n",
            "           4       1.00      0.99      1.00       258\n",
            "           5       1.00      1.00      1.00        90\n",
            "           6       0.91      1.00      0.95       102\n",
            "           7       1.00      1.00      1.00       108\n",
            "           8       0.94      0.95      0.94       108\n",
            "           9       1.00      0.99      1.00       174\n",
            "          10       0.99      0.96      0.98       198\n",
            "          11       1.00      1.00      1.00       102\n",
            "\n",
            "    accuracy                           0.98      1692\n",
            "   macro avg       0.97      0.98      0.98      1692\n",
            "weighted avg       0.98      0.98      0.98      1692\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_neighbors': range(1, 21),\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validated score:\", grid_search.best_score_)\n",
        "\n",
        "y_pred_knn = grid_search.predict(x_test)\n",
        "print(\"KNN Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_knn))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ce9ZgxJylnb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1dda2f3-9c17-4b58-931e-472e863acd22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       216\n",
            "           1       1.00      0.92      0.96        72\n",
            "           2       0.97      0.95      0.96       186\n",
            "           3       1.00      1.00      1.00        78\n",
            "           4       1.00      0.99      0.99       258\n",
            "           5       1.00      1.00      1.00        90\n",
            "           6       0.92      1.00      0.96       102\n",
            "           7       0.98      1.00      0.99       108\n",
            "           8       0.94      0.94      0.94       108\n",
            "           9       1.00      1.00      1.00       174\n",
            "          10       0.98      0.97      0.97       198\n",
            "          11       1.00      1.00      1.00       102\n",
            "\n",
            "    accuracy                           0.98      1692\n",
            "   macro avg       0.98      0.98      0.98      1692\n",
            "weighted avg       0.98      0.98      0.98      1692\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(x_train, y_train)\n",
        "rf.score(x_test, y_test)\n",
        "\n",
        "y_pred_rf = rf.predict(x_test)\n",
        "print(\"RF Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-XjnF-gmlnb4"
      },
      "outputs": [],
      "source": [
        "# from sklearn.externals import\n",
        "import pickle\n",
        "\n",
        "# pickle.dump(rf, 'rf_model.pkl', 'rb')\n",
        "with open('rf_model.pkl', 'wb') as file:\n",
        "    pickle.dump(rf, file)\n",
        "\n",
        "# pickle.dump(grid_search, 'knn_model.pkl', 'rb')\n",
        "with open('knn_model.pkl', 'wb') as file:\n",
        "    pickle.dump(grid_search, file)\n",
        "\n",
        "# pickle.dump(best_svm, 'svm_model.pkl', 'rb')\n",
        "with open('svm_model.pkl', 'wb') as file:\n",
        "    pickle.dump(best_svm, file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_path = \"/content/drive/MyDrive/CompVis Projek/UANGUVTERBARU/test/images/IMG_20241231_132045_jpg.rf.dd41bc73d9caf90be2af244d5f488eb9.jpg\"\n",
        "test_img = cv2.imread(test_img_path)\n",
        "if test_img is not None:\n",
        "    resized_test_img = cv2.resize(test_img, (512, 512))\n",
        "    test_features = extract_features(resized_test_img)\n",
        "    test_features = np.array(test_features).reshape(1, -1)\n",
        "\n",
        "    svm_result = best_svm.predict(test_features)[0]\n",
        "    knn_result = grid_search.predict(test_features)[0]\n",
        "    rf_result=rf.predict(test_features)[0]\n",
        "\n",
        "    print(\"Prediksi SVM:\", names[svm_result])\n",
        "    print(\"Prediksi RF:\", names[rf_result])\n",
        "    print(\"Prediksi KNN:\", names[knn_result])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZh3Shc-elzU",
        "outputId": "f4ac06f5-1904-45cd-f55f-62d94e911a6c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediksi SVM: 100 RIBU ASLI\n",
            "Prediksi RF: 10 RIBU ASLI\n",
            "Prediksi KNN: 10 RIBU ASLI\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}