{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BryanBM8/Rupiaj/blob/main/ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3uW9XL4lnbw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76-f6oQ_lnb0"
      },
      "outputs": [],
      "source": [
        "names = ['1 RIBU ASLI', '1 RIBU PALSU', '10 RIBU ASLI', '10 RIBU PALSU',\n",
        "         '100 RIBU ASLI', '100 RIBU PALSU', '20 RIBU ASLI', '20 RIBU PALSU',\n",
        "         '5 RIBU ASLI', '5 RIBU PALSU', '50 RIBU ASLI', '50 RIBU PALSU']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a2nme0slnb0"
      },
      "outputs": [],
      "source": [
        "def augment_image(image):\n",
        "    augmented_images = []\n",
        "\n",
        "    # Rotasi\n",
        "    for angle in [-30, 30]:\n",
        "        rotation_matrix = cv2.getRotationMatrix2D((image.shape[1] // 2, image.shape[0] // 2), angle, 1.0)\n",
        "        rotated = cv2.warpAffine(image, rotation_matrix, (image.shape[1], image.shape[0]))\n",
        "        augmented_images.append(rotated)\n",
        "\n",
        "    # Ubah kecerahan\n",
        "    for brightness_factor in [0.8, 1.0, 1.2]:\n",
        "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "        hsv[:, :, 2] = np.clip(hsv[:, :, 2] * brightness_factor, 0, 255).astype(np.uint8)\n",
        "        bright_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "        augmented_images.append(bright_img)\n",
        "\n",
        "    # Tambah noise\n",
        "    for _ in range(2):\n",
        "        noise = np.random.normal(0, 15, image.shape).astype(np.uint8)\n",
        "        noisy_img = cv2.add(image, noise)\n",
        "        augmented_images.append(noisy_img)\n",
        "\n",
        "    return augmented_images\n",
        "\n",
        "\n",
        "# microtext\n",
        "def extract_microtext(image_gray):\n",
        "    edges = cv2.Canny(image_gray, 50, 150)\n",
        "    return np.sum(edges) / edges.size\n",
        "\n",
        "# warna\n",
        "def extract_color(image):\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    hue_mean = np.mean(hsv[:, :, 0])\n",
        "    sat_mean = np.mean(hsv[:, :, 1])\n",
        "    val_mean = np.mean(hsv[:, :, 2])\n",
        "    return hue_mean, sat_mean, val_mean\n",
        "\n",
        "# benang pengaman\n",
        "def detect_thread(image_gray):\n",
        "    _, thresh = cv2.threshold(image_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 15))\n",
        "    thread = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel)\n",
        "    return np.sum(thread) / thread.size\n",
        "\n",
        "\n",
        "def extract_features(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray=cv2.equalizeHist(gray)\n",
        "    microtext_density = extract_microtext(gray)\n",
        "    hue, saturation, value = extract_color(image)\n",
        "    thread_density = detect_thread(gray)\n",
        "    return [ microtext_density, hue, saturation, value, thread_density]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5ssa1Dim_Tq",
        "outputId": "35254634-d745-4b7c-900c-2479a40eb404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjPWnvtwlnb1"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/drive/MyDrive/CompVis Projek/UANGUV\"\n",
        "\n",
        "def load_dataset_with_folder_structure(folder_path):\n",
        "    images_folder = os.path.join(folder_path, \"images\")\n",
        "    labels_folder = os.path.join(folder_path, \"labels\")\n",
        "\n",
        "    data = []\n",
        "    labels = []\n",
        "    count=0\n",
        "\n",
        "    for img_name in os.listdir(images_folder):\n",
        "        if img_name.endswith(\".jpg\"):\n",
        "            img_path = os.path.join(images_folder, img_name)\n",
        "            label_path = os.path.join(labels_folder, os.path.splitext(img_name)[0] + \".txt\")  # File label\n",
        "\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None and os.path.exists(label_path):  # Pastikan gambar dan label ada\n",
        "                resized_img = cv2.resize(img, (512, 512))  # Resize gambar\n",
        "                features = extract_features(resized_img)  # Ekstraksi fitur\n",
        "                data.append(features)\n",
        "\n",
        "                with open(label_path, \"r\") as f:\n",
        "                    first_line = f.readline().strip()  # Ambil baris pertama\n",
        "                    class_index = int(first_line.split()[0])  # Digit pertama sebagai label\n",
        "                    labels.append(class_index)\n",
        "\n",
        "                augmented_imgs = augment_image(resized_img)\n",
        "                for aug_img in augmented_imgs:\n",
        "                    aug_features = extract_features(aug_img)\n",
        "                    data.append(aug_features)\n",
        "                    labels.append(class_index)\n",
        "\n",
        "\n",
        "    return np.array(data, dtype=np.float32), np.array(labels, dtype=np.int32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8MWjAM-lnb1"
      },
      "outputs": [],
      "source": [
        "x_train, y_train= load_dataset_with_folder_structure(dataset_path+'/train/')\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "x_train, y_train= shuffle(x_train, y_train, random_state=42)\n",
        "x_test, y_test=load_dataset_with_folder_structure(dataset_path+'/test/')\n",
        "x_test, y_test=shuffle(x_test, y_test, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mn2Tgq9Mlnb2"
      },
      "outputs": [],
      "source": [
        "def balance_dataset_undersample(data, labels):\n",
        "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "    min_count = min(counts)\n",
        "\n",
        "    balanced_data = []\n",
        "    balanced_labels = []\n",
        "\n",
        "    label_to_data = {label: [] for label in unique_labels}\n",
        "    for d, l in zip(data, labels):\n",
        "        label_to_data[l].append(d)\n",
        "\n",
        "    for label in unique_labels:\n",
        "        samples = label_to_data[label][:min_count]\n",
        "        balanced_data.extend(samples)\n",
        "        balanced_labels.extend([label] * min_count)\n",
        "\n",
        "    return np.array(balanced_data, dtype=np.float32), np.array(balanced_labels, dtype=np.int32)\n",
        "\n",
        "\n",
        "x_train, y_train= balance_dataset_undersample(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lqxyy6Qvlnb2",
        "outputId": "9fdec393-89e1-4827-bbad-fb3738c7feee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jumlah data per label:\n",
            "Label 0: 2304 data\n",
            "Label 1: 2304 data\n",
            "Label 2: 2304 data\n",
            "Label 3: 2304 data\n",
            "Label 4: 2304 data\n",
            "Label 5: 2304 data\n",
            "Label 6: 2304 data\n",
            "Label 7: 2304 data\n",
            "Label 8: 2304 data\n",
            "Label 9: 2304 data\n",
            "Label 10: 2304 data\n",
            "Label 11: 2304 data\n"
          ]
        }
      ],
      "source": [
        "unique_labels, counts = np.unique(y_train, return_counts=True)\n",
        "\n",
        "print(\"Jumlah data per label:\")\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"Label {label}: {count} data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPqyTajUlnb3",
        "outputId": "65e0a535-2394-4d5f-d28e-df1e20f3bc38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=  59.4s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=  58.6s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=  58.7s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=  58.6s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=  60.0s\n",
            "Best Parameters: {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}\n",
            "Best Cross-Validation Accuracy: 0.3797744066547682\n",
            "Test Accuracy: 0.8928571428571429\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1],\n",
        "    'gamma': [1],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2, cv=5)\n",
        "grid.fit(x_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid.best_score_)\n",
        "\n",
        "best_svm = grid.best_estimator_\n",
        "print(\"Test Accuracy:\", best_svm.score(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTP9s5gilnb3",
        "outputId": "f88bfecb-b840-4d3e-f564-76cfc36b0e2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.93      0.95       288\n",
            "           1       1.00      0.77      0.87        96\n",
            "           2       1.00      0.89      0.94       232\n",
            "           3       1.00      0.96      0.98       104\n",
            "           4       0.99      0.93      0.96       344\n",
            "           5       0.35      1.00      0.52       120\n",
            "           6       1.00      0.79      0.88       120\n",
            "           7       1.00      0.93      0.96       144\n",
            "           8       1.00      0.87      0.93       120\n",
            "           9       1.00      0.94      0.97       232\n",
            "          10       1.00      0.80      0.89       248\n",
            "          11       1.00      0.82      0.90       136\n",
            "\n",
            "    accuracy                           0.89      2184\n",
            "   macro avg       0.94      0.89      0.90      2184\n",
            "weighted avg       0.96      0.89      0.91      2184\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_svm = best_svm.predict(x_test)\n",
        "print(\"KNN Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_svm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEUzeNlqlnb4",
        "outputId": "c10c1505-2a97-4282-8bff-aed5d9a53e3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'uniform'}\n",
            "Best cross-validated score: 0.9228875333315673\n",
            "KNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.97       288\n",
            "           1       0.89      0.92      0.90        96\n",
            "           2       0.99      1.00      0.99       232\n",
            "           3       1.00      1.00      1.00       104\n",
            "           4       1.00      0.99      0.99       344\n",
            "           5       1.00      1.00      1.00       120\n",
            "           6       0.96      1.00      0.98       120\n",
            "           7       1.00      1.00      1.00       144\n",
            "           8       0.96      0.99      0.98       120\n",
            "           9       1.00      0.98      0.99       232\n",
            "          10       0.99      0.98      0.99       248\n",
            "          11       1.00      1.00      1.00       136\n",
            "\n",
            "    accuracy                           0.98      2184\n",
            "   macro avg       0.98      0.98      0.98      2184\n",
            "weighted avg       0.98      0.98      0.98      2184\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_neighbors': range(1, 21),\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validated score:\", grid_search.best_score_)\n",
        "\n",
        "y_pred_knn = grid_search.predict(x_test)\n",
        "print(\"KNN Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_knn))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce9ZgxJylnb4",
        "outputId": "ce5d3d48-e909-44b9-c7a1-80d27f4b9b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       288\n",
            "           1       1.00      0.92      0.96        96\n",
            "           2       0.99      1.00      0.99       232\n",
            "           3       0.98      1.00      0.99       104\n",
            "           4       1.00      0.98      0.99       344\n",
            "           5       1.00      1.00      1.00       120\n",
            "           6       0.97      1.00      0.98       120\n",
            "           7       1.00      1.00      1.00       144\n",
            "           8       1.00      0.97      0.99       120\n",
            "           9       1.00      0.99      1.00       232\n",
            "          10       0.98      0.98      0.98       248\n",
            "          11       1.00      1.00      1.00       136\n",
            "\n",
            "    accuracy                           0.99      2184\n",
            "   macro avg       0.99      0.99      0.99      2184\n",
            "weighted avg       0.99      0.99      0.99      2184\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(x_train, y_train)\n",
        "rf.score(x_test, y_test)\n",
        "\n",
        "y_pred_rf = rf.predict(x_test)\n",
        "print(\"SVM Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XjnF-gmlnb4"
      },
      "outputs": [],
      "source": [
        "# from sklearn.externals import\n",
        "import pickle\n",
        "\n",
        "# pickle.dump(rf, 'rf_model.pkl', 'rb')\n",
        "with open('rf_model.pkl', 'wb') as file:\n",
        "    pickle.dump(rf, file)\n",
        "\n",
        "# pickle.dump(grid_search, 'knn_model.pkl', 'rb')\n",
        "with open('knn_model.pkl', 'wb') as file:\n",
        "    pickle.dump(grid_search, file)\n",
        "\n",
        "# pickle.dump(best_svm, 'svm_model.pkl', 'rb')\n",
        "with open('svm_model.pkl', 'wb') as file:\n",
        "    pickle.dump(best_svm, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIlve32slnb4",
        "outputId": "0b54c5ff-3197-490f-c9b6-e18781add85e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediksi SVM: 100 RIBU PALSU\n",
            "Prediksi RF: 100 RIBU ASLI\n",
            "Prediksi KNN: 10 RIBU ASLI\n"
          ]
        }
      ],
      "source": [
        "test_img_path = \"./PROJECT DATA UANG.v3i.yolov11/valid/images/WIN_20240626_16_38_51_Pro_mp4-0000_jpg.rf.e63359b40e200d0dfed497544f92d64e.jpg\"\n",
        "test_img = cv2.imread(test_img_path)\n",
        "if test_img is not None:\n",
        "    resized_test_img = cv2.resize(test_img, (512, 512))\n",
        "    test_features = extract_features(resized_test_img)\n",
        "    test_features = np.array(test_features).reshape(1, -1)\n",
        "\n",
        "    svm_result = best_svm.predict(test_features)[0]\n",
        "    knn_result = grid_search.predict(test_features)[0]\n",
        "    rf_result=rf.predict(test_features)[0]\n",
        "\n",
        "    print(\"Prediksi SVM:\", names[svm_result])\n",
        "    print(\"Prediksi RF:\", names[rf_result])\n",
        "    print(\"Prediksi KNN:\", names[knn_result])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvM3Eobdlnb5"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# import os\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "# from tensorflow.keras import layers, models, optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp-SESpFlnb5"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.applications import ResNet50\n",
        "# from tensorflow.keras.models import Model\n",
        "\n",
        "# # Definisikan model ResNet50 sebagai backbone\n",
        "# base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(512, 512, 3))\n",
        "\n",
        "# # Tambahkan custom layers di atas backbone\n",
        "# model = models.Sequential([\n",
        "#     base_model,  # ResNet50 sebagai backbone\n",
        "#     layers.GlobalAveragePooling2D(),  # Global average pooling untuk meratakan output ResNet50\n",
        "#     layers.Dense(units=4096, activation=\"relu\"),  # Fully connected layer pertama\n",
        "#     layers.Dense(units=4096, activation=\"relu\"),  # Fully connected layer kedua\n",
        "#     layers.Dense(units=1000, activation=\"softmax\")  # Output layer untuk 1000 kelas\n",
        "# ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYEwl2Y0lnb5"
      },
      "outputs": [],
      "source": [
        "# model.compile(optimizer='adam',\n",
        "#               loss='sparse_categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0yc3gNClnb5"
      },
      "outputs": [],
      "source": [
        "# x_val, y_val=load_dataset_with_folder_structure(dataset_path+'/valid/')\n",
        "# x_val, y_val=shuffle(x_val, y_val, random_state=42)\n",
        "\n",
        "\n",
        "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "# history = model.fit(x_train,y_train,epochs=100,validation_data=(x_val,y_val), batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Srz828bClnb5"
      },
      "outputs": [],
      "source": [
        "# loss, accuracy = model.evaluate(x_test,y_test)\n",
        "# print(f'loss = {loss}')\n",
        "# print(f'accuracy = {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U7KtnfUlnb5"
      },
      "outputs": [],
      "source": [
        "# cnn_result=model.predict(x_test)\n",
        "# predicted_class_indices = np.argmax(cnn_result, axis=-1)\n",
        "\n",
        "\n",
        "# correct_count = np.sum(predicted_class_indices == y_test)\n",
        "# accuracy = correct_count / len(y_test)\n",
        "# for i, (predicted_idx, true_idx) in enumerate(zip(predicted_class_indices, y_test)):\n",
        "#     print(f\"Sample {i}: Prediksi = {names[predicted_idx]}, Asli = {names[true_idx]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEMzeEHglnb6"
      },
      "outputs": [],
      "source": [
        "# model.save('vgg16_model.h5')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
